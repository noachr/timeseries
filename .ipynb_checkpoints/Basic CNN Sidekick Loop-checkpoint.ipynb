{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Expects timeseries.py in same folder as nb. \n",
    "from fastai.vision import *\n",
    "from pathlib import Path\n",
    "import pdb\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from timeseries import TimeSeriesItem, TimeSeriesList, UCRArchive\n",
    "from scipy.signal import resample\n",
    "from IPython.display import clear_output\n",
    "import fastai.utils.mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init UCR archive helper class\n",
    "ucr = UCRArchive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All input is resampled down to a length of 96\n",
    "class Resample(PreProcessor):\n",
    "    def process_one(self,item):\n",
    "        return np.concatenate([item[[0]],resample(item[1:],96)]) if len(item) > 97 else item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions, modified to 1d from fastai\n",
    "def create_head_1d(nf:int, nc:int, lin_ftrs:Optional[Collection[int]]=None, ps:Floats=0.5, bn_final:bool=False):\n",
    "    \"Model head that takes `nf` features, runs through `lin_ftrs`, and about `nc` classes.\"\n",
    "    lin_ftrs = [nf, 512, nc] if lin_ftrs is None else [nf] + lin_ftrs + [nc]\n",
    "    ps = listify(ps)\n",
    "    if len(ps)==1: ps = [ps[0]/2] * (len(lin_ftrs)-2) + ps\n",
    "    actns = [nn.ReLU(inplace=True)] * (len(lin_ftrs)-2) + [None]\n",
    "    layers = []\n",
    "    for ni,no,p,actn in zip(lin_ftrs[:-1],lin_ftrs[1:],ps,actns):\n",
    "        layers += bn_drop_lin(ni,no,True,p,actn)\n",
    "    if bn_final: layers.append(nn.BatchNorm1d(lin_ftrs[-1], momentum=0.01))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def conv1d(ni:int, nf:int, ks:int=3, stride:int=1, padding:int=None, bias=False, init:LayerFunc=nn.init.kaiming_normal_) -> nn.Conv1d:\n",
    "    \"Create and initialize `nn.Conv1d` layer. `padding` defaults to `ks//2`.\"\n",
    "    if padding is None: padding = ks//2\n",
    "    return init_default(nn.Conv1d(ni, nf, kernel_size=ks, stride=stride, padding=padding, bias=bias), init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the hero network, which serves as a backbone to all the other models\n",
    "class HeroConvnet(nn.Module):\n",
    "    def __init__(self, num_layers=8, start_nf=8):\n",
    "        super().__init__()\n",
    "        \n",
    "        layers = [nn.Sequential(conv1d(1,start_nf,3,1),nn.ReLU())] #First layer is stride 1, creates initial set of filters\n",
    "        nf = start_nf\n",
    "        for _ in range(num_layers): #Then num_layers stride 2 convs, doubling the number of filters each layer\n",
    "            layers.append(nn.Sequential(conv1d(nf,nf*2,3,2),nn.ReLU()))\n",
    "            nf *= 2\n",
    "        \n",
    "        self.nf = nf\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        self.avg = nn.AdaptiveAvgPool1d(1)\n",
    "            \n",
    "            \n",
    "    def forward(self, x):\n",
    "        actvns = [x]\n",
    "        \n",
    "        for l in self.layers:\n",
    "            actvns.append(l(actvns[-1]))\n",
    "\n",
    "        return self.avg(actvns[-1]), actvns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicClassifier(nn.Module):\n",
    "    def __init__(self,numClasses):\n",
    "        super().__init__()\n",
    "        self.conv = HeroConvnet()\n",
    "        self.out = create_head_1d(self.conv.nf,numClasses,ps=0.0)\n",
    "              \n",
    "    def forward(self,ts):\n",
    "        ts = self.conv(ts.unsqueeze(1))[0].squeeze(-1)\n",
    "        return self.out(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic variational autoencoder with hero net serving as encoder and a few linear layers as decoder\n",
    "class TSAutoencoder(nn.Module):\n",
    "    def __init__(self,seqLen,latentDim=12):\n",
    "        super().__init__()\n",
    "        self.conv = HeroConvnet()\n",
    "        self.mean = torch.nn.Linear(self.conv.nf,latentDim)\n",
    "        self.logvar = torch.nn.Linear(self.conv.nf,latentDim)\n",
    "        self.out = create_head_1d(latentDim,seqLen,lin_ftrs=[256,512],ps=0.0)\n",
    "\n",
    "    def forward(self,ts):\n",
    "        seqLen = ts.shape[1]\n",
    "        ts, _ = self.conv(ts.unsqueeze(1))\n",
    "        ts = ts.squeeze(-1)\n",
    "\n",
    "        mean, logvar = self.mean(ts), self.logvar(ts)\n",
    "          \n",
    "        ls = mean\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5 * logvar)\n",
    "            eps = torch.randn_like(std)\n",
    "            ls = eps.mul(std).add_(mean)        \n",
    "        return self.out(ls), mean, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The sidekick network mirrors the structure of the hero, but concats the output of each layer of the hero to the input of each \n",
    "#layer of the sidekick\n",
    "class SidekickConvnet(nn.Module):\n",
    "    def __init__(self, num_classes, num_layers=8, start_nf=8, start_nf_hero=8):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hero = HeroConvnet(num_layers,start_nf_hero)\n",
    "        \n",
    "        layers = [nn.Sequential(conv1d(1,start_nf,3,1),nn.ReLU())] \n",
    "        nf = start_nf\n",
    "        nf_hero = start_nf_hero\n",
    "        for _ in range(num_layers):\n",
    "            layers.append(nn.Sequential(conv1d(nf+nf_hero,nf*2,3,2),nn.ReLU()))\n",
    "            nf *= 2\n",
    "            nf_hero *= 2\n",
    "        \n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        self.avg = nn.AdaptiveAvgPool1d(1)\n",
    "        self.out = create_head_1d(nf + nf_hero,num_classes,ps=0.0)\n",
    "    \n",
    "    def forward(self,ts):\n",
    "        ts = ts.unsqueeze(1)\n",
    "        pt, actvns = self.hero(ts)\n",
    "        \n",
    "        x = self.layers[0](ts)\n",
    "        for l,a in zip(self.layers[1:],actvns):\n",
    "            x = l(torch.cat([x,a],dim=1))\n",
    "            \n",
    "        x = torch.cat([self.avg(x),pt],dim=1).squeeze(-1)\n",
    "        return self.out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAELoss(torch.nn.Module):\n",
    "    def __init__(self,beta=1.0):\n",
    "        super().__init__()\n",
    "        self.beta = beta\n",
    "    def forward(self,p,target):\n",
    "        pred,mean,logvar = p\n",
    "        self.mse = torch.nn.functional.mse_loss(pred,target,reduction=\"sum\")\n",
    "        self.kld = self.beta * -0.5 * torch.sum(1+logvar-mean.pow(2)-logvar.exp())\n",
    "        return self.mse + self.kld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@fastai.utils.mem.gpu_mem_restore\n",
    "def EvaluateDataset(dataset_name):\n",
    "    out = [dataset_name]\n",
    "    \n",
    "    try:\n",
    "        src = TimeSeriesList.from_csv_list(ucr.get_csv_files(dataset_name),labelCol=0)#,processor=Resample())\n",
    "        valIdxs = np.random.choice(len(src.items),int(len(src.items)*0.3),replace=False)\n",
    "        data = src.split_by_idx(valIdxs)\n",
    "        data = data.label_from_col()\n",
    "        idxs = np.random.choice(len(data.x),size=len(data.x)//10,replace=False)\n",
    "        bs = min(64,len(data.x)//50)\n",
    "        data.x.items = data.train.x.items[idxs]\n",
    "        data.y.items = data.train.y.items[idxs]\n",
    "        data = data.databunch(bs=bs,num_workers=0)\n",
    "\n",
    "        src = TimeSeriesList.from_csv_list(ucr.get_csv_files(dataset_name),labelCol=0)#,processor=Resample())\n",
    "        dataAE = src.split_by_idx(valIdxs)\n",
    "        dataAE = dataAE.label_from_self()\n",
    "        dataAE = dataAE.databunch(bs=bs,num_workers=0)\n",
    "\n",
    "        learnBase = Learner(data,BasicClassifier(data.train_ds.c),loss_func=F.cross_entropy,metrics=[accuracy])\n",
    "        learnBase.fit_one_cycle(20,1e-3,wd=0.2)\n",
    "        out.append(max([m[0].item() for m in learnBase.recorder.metrics]))\n",
    "\n",
    "        learnAE = Learner(dataAE,TSAutoencoder(len(data.train_ds[0][0].data),latentDim=12),loss_func=VAELoss())\n",
    "        learnAE.fit_one_cycle(20,1e-2)\n",
    "        out.append(learnAE.validate(dataAE.train_dl)[0])\n",
    "        \n",
    "        learnSidekick = Learner(data,SidekickConvnet(data.train_ds.c), loss_func=F.cross_entropy,metrics=[accuracy],\n",
    "                            callback_fns=BnFreeze,bn_wd=False,train_bn=False)\n",
    "        learnSidekick.split([learnSidekick.model.hero,learnSidekick.model.layers[0],learnSidekick.model.out])\n",
    "        learnSidekick.model.hero.load_state_dict(learnAE.model.conv.state_dict())\n",
    "        learnSidekick.freeze_to(1)\n",
    "        learnSidekick.fit_one_cycle(20,1e-3,wd=0.2)\n",
    "        learnSidekick.fit_one_cycle(20,1e-4,wd=0.2)\n",
    "        out.append(max([m[0].item() for m in learnSidekick.recorder.metrics]))\n",
    "        \n",
    "        learnAE.fit_one_cycle(200,1e-3)\n",
    "        out.append(learnAE.validate(dataAE.train_dl)[0])\n",
    "\n",
    "\n",
    "        learnDT = Learner(data,BasicClassifier(data.train_ds.c),loss_func=F.cross_entropy,metrics=[accuracy],\n",
    "                     callback_fns=BnFreeze,bn_wd=False,train_bn=False)\n",
    "        learnDT.split([*learnDT.model.conv.layers,learnDT.model.conv.avg,learnDT.model.out])\n",
    "        learnDT.model.conv.load_state_dict(learnAE.model.conv.state_dict())\n",
    "        learnDT.freeze_to(-1)\n",
    "        learnDT.fit_one_cycle(20,1e-2)\n",
    "        out.append(max([m[0].item() for m in learnDT.recorder.metrics]))\n",
    "        learnDT.unfreeze()\n",
    "        learnDT.fit_one_cycle(20,1e-3)\n",
    "        out.append(max([m[0].item() for m in learnDT.recorder.metrics]))\n",
    "        \n",
    "        learnSidekickBase = Learner(data,SidekickConvnet(data.train_ds.c), loss_func=F.cross_entropy,metrics=[accuracy],\n",
    "                    callback_fns=BnFreeze,bn_wd=False,train_bn=False)\n",
    "        learnSidekickBase.fit_one_cycle(20,1e-3,wd=0.2)\n",
    "        learnSidekickBase.fit_one_cycle(20,1e-4,wd=0.2)\n",
    "        out.append(max([m[0].item() for m in learnSidekickBase.recorder.metrics]))\n",
    "\n",
    "        learnSidekick = Learner(data,SidekickConvnet(data.train_ds.c), loss_func=F.cross_entropy,metrics=[accuracy],\n",
    "                            callback_fns=BnFreeze,bn_wd=False,train_bn=False)\n",
    "        learnSidekick.split([learnSidekick.model.hero,learnSidekick.model.layers[0],learnSidekick.model.out])\n",
    "        learnSidekick.model.hero.load_state_dict(learnAE.model.conv.state_dict())\n",
    "        learnSidekick.freeze_to(1)\n",
    "        learnSidekick.fit_one_cycle(20,1e-3,wd=0.2)\n",
    "        learnSidekick.fit_one_cycle(20,1e-4,wd=0.2)\n",
    "        out.append(max([m[0].item() for m in learnSidekick.recorder.metrics]))\n",
    "    except:\n",
    "        pass\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating ArrowHead\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Total time: 00:04 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>1.065368</th>\n",
       "    <th>1.074859</th>\n",
       "    <th>0.571429</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.903839</th>\n",
       "    <th>1.034353</th>\n",
       "    <th>0.666667</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.795334</th>\n",
       "    <th>0.950420</th>\n",
       "    <th>0.666667</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.701934</th>\n",
       "    <th>0.891487</th>\n",
       "    <th>0.587302</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>0.801263</th>\n",
       "    <th>1.010493</th>\n",
       "    <th>0.492063</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>6</th>\n",
       "    <th>0.842876</th>\n",
       "    <th>1.017480</th>\n",
       "    <th>0.412698</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>7</th>\n",
       "    <th>0.802448</th>\n",
       "    <th>1.617448</th>\n",
       "    <th>0.444444</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>8</th>\n",
       "    <th>0.755297</th>\n",
       "    <th>3.447189</th>\n",
       "    <th>0.333333</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>9</th>\n",
       "    <th>0.730016</th>\n",
       "    <th>1.808319</th>\n",
       "    <th>0.365079</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>10</th>\n",
       "    <th>0.704557</th>\n",
       "    <th>1.387421</th>\n",
       "    <th>0.444444</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>11</th>\n",
       "    <th>0.702435</th>\n",
       "    <th>0.912800</th>\n",
       "    <th>0.571429</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>12</th>\n",
       "    <th>0.709337</th>\n",
       "    <th>1.021534</th>\n",
       "    <th>0.539683</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>13</th>\n",
       "    <th>0.702154</th>\n",
       "    <th>1.032145</th>\n",
       "    <th>0.603175</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>14</th>\n",
       "    <th>0.739917</th>\n",
       "    <th>0.902093</th>\n",
       "    <th>0.634921</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>15</th>\n",
       "    <th>0.733792</th>\n",
       "    <th>0.884892</th>\n",
       "    <th>0.634921</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>16</th>\n",
       "    <th>0.779136</th>\n",
       "    <th>0.868271</th>\n",
       "    <th>0.666667</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>17</th>\n",
       "    <th>0.756288</th>\n",
       "    <th>0.832343</th>\n",
       "    <th>0.666667</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>18</th>\n",
       "    <th>0.765916</th>\n",
       "    <th>0.862535</th>\n",
       "    <th>0.619048</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>19</th>\n",
       "    <th>0.777990</th>\n",
       "    <th>0.879429</th>\n",
       "    <th>0.619048</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>20</th>\n",
       "    <th>0.757544</th>\n",
       "    <th>0.882656</th>\n",
       "    <th>0.619048</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='7' class='' max='20', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      35.00% [7/20 00:10<00:18]\n",
       "    </div>\n",
       "    \n",
       "<table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>485.263062</th>\n",
       "    <th>354.287201</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>243.872025</th>\n",
       "    <th>92.324875</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>278.888550</th>\n",
       "    <th>1174.498779</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>225.445160</th>\n",
       "    <th>152.532867</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>166.786728</th>\n",
       "    <th>87.444374</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>6</th>\n",
       "    <th>118.794945</th>\n",
       "    <th>100.677917</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>7</th>\n",
       "    <th>93.651848</th>\n",
       "    <th>88.328949</th>\n",
       "  </tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='45' class='' max='74', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      60.81% [45/74 00:00<00:00 143.7104]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = []\n",
    "skip = [\"ACSF1\",\"AllGestureWiimoteX\",\"AllGestureWiimoteY\",\"AllGestureWiimoteZ\"]\n",
    "for ds in ucr.list_datasets():\n",
    "    if ds in skip: continue\n",
    "    print(f\"Evaluating {ds}\")\n",
    "    #for _ in range(4): results.append(EvaluateDataset(ds))\n",
    "    results.append(EvaluateDataset(ds))\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results,columns=[\"Name\",\"Baseline\",\"Head\",\"Direct\",\"Sidekick Base\",\"Sidekick\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby(by=\"Name\").mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Gain\"] = df[\"Sidekick\"] - df[[\"Baseline\",\"Sidekick Base\"]].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Sidekick Gain\"] = df[\"Sidekick\"] - df[[\"Head\",\"Direct\"]].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(\"Gain\",ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
