{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Expects timeseries.py in same folder as nb. \n",
    "from fastai.vision import *\n",
    "from pathlib import Path\n",
    "import pdb\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from timeseries import TimeSeriesItem, TimeSeriesList, UCRArchive\n",
    "from scipy.signal import resample\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.utils.linear_assignment_ import linear_assignment\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init UCR archive helper class\n",
    "ucr = UCRArchive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Create dataloaders\n",
    "To run this notebook, you'll need the archive available here <https://www.cs.ucr.edu/~eamonn/time_series_data_2018/>\n",
    "The password to the archive is 'someone'. Place the unziped directory in the same location as this nb.\n",
    "\n",
    "The UCR Time Series Classification Archive contains 128 univariate timeseries data sets, of varying lengths and number of classes. They are presorted into training and validation sets, however the ratio between the two differs wildly from set to set. Below, I combine all the data and make my own validation set, set at 30% of the total data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Below are some datasets that seem to have good transfer properties:\n",
    "#CinCECGTorso, MedicalImages, TwoPatterns, InsectWingbeatSound, UWaveGestureLibraryAll, WordSynonyms, SemgHandGenderCh2\n",
    "dataset_name = \"InsectWingbeatSound\"\n",
    "#Visualize class distribution of initial train and validation sets\n",
    "vc = ucr.category_distribution(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All input is resampled down to a length of 96\n",
    "class Resample(PreProcessor):\n",
    "    def process_one(self,item):\n",
    "        return np.concatenate([item[[0]],resample(item[1:],96)]) if len(item) > 97 else item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we create the classification dataset. The fastai data_block api doesn't directly support what I am trying to do, namely\n",
    "#remove most of the labels AFTER creating the validation set. Thus, a bit of hackery is required. \n",
    "#Not sure about the warning, seems to be ok...\n",
    "\n",
    "src = TimeSeriesList.from_csv_list(ucr.get_csv_files(dataset_name),labelCol=0,processor=Resample())\n",
    "data = src.split_by_csv_name([f\"{dataset_name}_TEST.tsv\"])\n",
    "data = data.label_from_col()\n",
    "bs = min(64,len(data.x)//50)\n",
    "data = data.databunch(bs=bs,num_workers=0)\n",
    "len(data.train_ds) #We end up with a training data set consisting of 10% of the training data as well as the full validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we create the autocoder dataset. The differences are the data is labeled with itself, and that we use \n",
    "#the full amount of training data\n",
    "\n",
    "src = TimeSeriesList.from_csv_list(ucr.get_csv_files(dataset_name),labelCol=0,processor=Resample())\n",
    "dataAE = src.split_by_csv_name([f\"{dataset_name}_TEST.tsv\"])\n",
    "dataAE = dataAE.label_from_col()\n",
    "dataAE = dataAE.databunch(bs=bs,num_workers=0)\n",
    "len(dataAE.train_ds) #Should be ~10x the classification size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show a few inputs from the dataset\n",
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions, modified to 1d from fastai\n",
    "def create_head_1d(nf:int, nc:int, lin_ftrs:Optional[Collection[int]]=None, ps:Floats=0.5, bn_final:bool=False):\n",
    "    \"Model head that takes `nf` features, runs through `lin_ftrs`, and about `nc` classes.\"\n",
    "    lin_ftrs = [nf, 512, nc] if lin_ftrs is None else [nf] + lin_ftrs + [nc]\n",
    "    ps = listify(ps)\n",
    "    if len(ps)==1: ps = [ps[0]/2] * (len(lin_ftrs)-2) + ps\n",
    "    actns = [nn.ReLU(inplace=True)] * (len(lin_ftrs)-2) + [None]\n",
    "    layers = []\n",
    "    for ni,no,p,actn in zip(lin_ftrs[:-1],lin_ftrs[1:],ps,actns):\n",
    "        layers += bn_drop_lin(ni,no,True,p,actn)\n",
    "    if bn_final: layers.append(nn.BatchNorm1d(lin_ftrs[-1], momentum=0.01))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def conv1d(ni:int, nf:int, ks:int=3, stride:int=1, padding:int=None, bias=False, init:LayerFunc=nn.init.kaiming_normal_) -> nn.Conv1d:\n",
    "    \"Create and initialize `nn.Conv1d` layer. `padding` defaults to `ks//2`.\"\n",
    "    if padding is None: padding = ks//2\n",
    "    return init_default(nn.Conv1d(ni, nf, kernel_size=ks, stride=stride, padding=padding, bias=bias), init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the hero network, which serves as a backbone to all the other models\n",
    "class HeroConvnet(nn.Module):\n",
    "    def __init__(self, num_layers=3, start_nf=16, drop_p = 0.0):\n",
    "        super().__init__()\n",
    "        \n",
    "        layers = [nn.Sequential(conv1d(1,start_nf,3,1),nn.LeakyReLU(0.2))] #First layer is stride 1, creates initial set of filters\n",
    "        nf = start_nf\n",
    "        for d in np.linspace(drop_p/10,drop_p,num_layers): #Then num_layers stride 2 convs, doubling the number of filters each layer\n",
    "            layers.append(nn.Sequential(conv1d(nf,nf*2,3,2),nn.LeakyReLU(0.2)))\n",
    "            nf *= 2\n",
    "        \n",
    "        self.nf = nf\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        self.avg = nn.AdaptiveAvgPool1d(1)\n",
    "            \n",
    "            \n",
    "    def forward(self, x):\n",
    "        actvns = [x]\n",
    "        \n",
    "        for l in self.layers:\n",
    "            actvns.append(l(actvns[-1]))\n",
    "\n",
    "        return self.avg(actvns[-1]), actvns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicClassifier(nn.Module):\n",
    "    def __init__(self,numClasses,num_layers=3,start_nf=16,drop_p=0.0):\n",
    "        super().__init__()\n",
    "        self.conv = HeroConvnet(num_layers,start_nf,drop_p=drop_p)\n",
    "        self.out = create_head_1d(self.conv.nf,numClasses,ps=0.0)\n",
    "              \n",
    "    def forward(self,ts):\n",
    "        ts = self.conv(ts.unsqueeze(1))[0].squeeze(-1)\n",
    "        return self.out(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic variational autoencoder with hero net serving as encoder and a few linear layers as decoder\n",
    "class TSAutoencoder(nn.Module):\n",
    "    def __init__(self,seqLen,latentDim=12,num_layers=3,start_nf=16):\n",
    "        super().__init__()\n",
    "        self.conv = HeroConvnet(num_layers,start_nf)\n",
    "        self.ls = torch.nn.Linear(self.conv.nf,latentDim)\n",
    "        self.out = create_head_1d(latentDim,seqLen,lin_ftrs=[256,512],ps=0.0)\n",
    "        \n",
    "    def getLS(self,ts):\n",
    "        ts, _ = self.conv(ts.unsqueeze(1))\n",
    "        ts = ts.squeeze(-1)\n",
    "        ls = self.ls(ts)\n",
    "        return ls\n",
    "\n",
    "    def forward(self,ts):\n",
    "        seqLen = ts.shape[1]\n",
    "        ots = ts\n",
    "        ts, _ = self.conv(ts.unsqueeze(1))\n",
    "        ts = ts.squeeze(-1)\n",
    "\n",
    "        ls = self.ls(ts)\n",
    "               \n",
    "        return self.out(ls), ots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cluster(nn.Module):\n",
    "    def __init__(self,num_classes,num_layers,start_nf):\n",
    "        super().__init__()\n",
    "        self.conv = HeroConvnet(num_layers,start_nf)\n",
    "        self.ps = nn.Linear(self.conv.nf,num_classes)\n",
    "        \n",
    "    def forward(self,ts):\n",
    "        ts, _ = self.conv(ts.unsqueeze(1))\n",
    "        return self.ps(ts.squeeze(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MOA(nn.Module):\n",
    "    def __init__(self,num_classes,seqLen,latentDim=12,num_layers=3,start_nf=16):\n",
    "        super().__init__()\n",
    "        self.aes = nn.ModuleList([TSAutoencoder(seqLen,latentDim,6,4) for _ in range(num_classes)])\n",
    "        self.cluster = Cluster(num_classes,num_layers,start_nf)\n",
    "        \n",
    "    def getCluster(self,ts):\n",
    "        ps = self.cluster(ts)\n",
    "        ps = torch.softmax(ps,dim=1)\n",
    "        return torch.argmax(ps,dim=1)\n",
    "        \n",
    "    def forward(self, ts):\n",
    "        recon = [ae(ts)[0] for ae in self.aes]\n",
    "        ps = self.cluster(ts)\n",
    "        return ps, recon, ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The sidekick network mirrors the structure of the hero, but concats the output of each layer of the hero to the input of each \n",
    "#layer of the sidekick\n",
    "class SidekickConvnet(nn.Module):\n",
    "    def __init__(self, num_classes, num_layers=3, start_nf=16, start_nf_hero=16):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hero = HeroConvnet(num_layers,start_nf_hero)\n",
    "        \n",
    "        layers = [nn.Sequential(conv1d(1,start_nf,3,1),nn.LeakyReLU(0.2))] \n",
    "        nf = start_nf\n",
    "        nf_hero = start_nf_hero\n",
    "        for _ in range(num_layers):\n",
    "            layers.append(nn.Sequential(conv1d(nf+nf_hero,nf*2,3,2),nn.LeakyReLU(0.2)))\n",
    "            nf *= 2\n",
    "            nf_hero *= 2\n",
    "        \n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        #self.ll = conv1d(nf+nf_hero,nf+nf_hero,3,1)\n",
    "        self.avg = nn.AdaptiveAvgPool1d(1)\n",
    "        self.out = create_head_1d(nf + nf_hero,num_classes,ps=0.0)\n",
    "    \n",
    "    def forward(self,ts):\n",
    "        ts = ts.unsqueeze(1)\n",
    "        pt, actvns = self.hero(ts)\n",
    "        \n",
    "        x = self.layers[0](ts)\n",
    "        for l,a in zip(self.layers[1:],actvns):\n",
    "            x = l(torch.cat([x,a],dim=1))\n",
    "            \n",
    "        x = torch.cat([self.avg(x),pt],dim=1).squeeze(-1)\n",
    "        #x = self.ll(torch.cat([x,actvns[-1]],dim=1))\n",
    "        #x = self.avg(x).squeeze(-1)\n",
    "        return self.out(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Get Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learnBase = Learner(data,BasicClassifier(data.train_ds.c,8,8,drop_p=0.0),loss_func=F.cross_entropy,metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run one batch through the model to make sure the output size is correct\n",
    "learnBase.model(next(iter(data.train_dl))[0]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Learning rate finder\n",
    "learnBase.lr_find()\n",
    "learnBase.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learnBase.fit_one_cycle(20,1e-3,wd=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusterAccuracy(LearnerCallback):\n",
    "    _order=-20\n",
    "    def __init__(self,learn):\n",
    "        super().__init__(learn)\n",
    "    def on_train_begin(self, **kwargs):\n",
    "        self.learn.recorder.add_metric_names([\"cluster_accuracy\"])\n",
    "        \n",
    "    def on_epoch_end(self,**kwargs):\n",
    "        self.learn.model.eval()\n",
    "        dl = torch.utils.data.DataLoader(self.learn.data.train_ds,batch_size=64,collate_fn=data_collate)\n",
    "        labels_pred, labels_true = [],[]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for ts,labels in iter(dl):\n",
    "                ts = ts.cuda()\n",
    "                labels_pred.append(self.learn.model.getCluster(ts).cpu().detach().numpy())\n",
    "                labels_true.append(labels.numpy())\n",
    "        labels_pred = np.concatenate(labels_pred)\n",
    "        labels_true = np.concatenate(labels_true)\n",
    "        labels_true = labels_true.astype(np.int64)\n",
    "        assert labels_pred.size == labels_true.size\n",
    "        \n",
    "        D = max(labels_pred.max(), labels_true.max()) + 1\n",
    "        w = np.zeros((D, D), dtype=np.int64)\n",
    "        for i in range(labels_pred.size):\n",
    "            w[labels_pred[i], labels_true[i]] += 1\n",
    "        ind = linear_assignment(w.max() - w)\n",
    "        #self.metric = torch.tensor(sum([w[i, j] for i, j in ind]) * 1.0 / labels_pred.size)\n",
    "        self.learn.recorder.add_metrics([torch.tensor(sum([w[i, j] for i, j in ind]) * 1.0 / labels_pred.size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AELoss(pred,target):\n",
    "    return F.mse_loss(pred[0],pred[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MOALoss(torch.nn.Module):\n",
    "    def forward(self,p,target):\n",
    "        p,recon, ts = p\n",
    "        p = torch.softmax(p,dim=1)\n",
    "        rerrs = torch.stack([torch.exp(-0.5 * ((ts-r)**2).sum(dim=1)) for r in recon],dim=1)\n",
    "        berr = (p * rerrs).sum(dim=1)\n",
    "        berr = torch.log(berr)\n",
    "        return -berr.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learnAE = Learner(dataAE,MOA(data.train_ds.c,len(data.train_ds[0][0].data),latentDim=12,num_layers=8,start_nf=8),\n",
    "                  loss_func=MOALoss(),callback_fns=[ClusterAccuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learnAE.model(next(iter(data.train_dl))[0])[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learnAEInit = Learner(dataAE,TSAutoencoder(len(data.train_ds[0][0].data),num_layers=8,start_nf=8),loss_func=AELoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learnAEInit.fit_one_cycle(20,1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learnAEInit.model.eval()\n",
    "out = []\n",
    "dl = torch.utils.data.DataLoader(dataAE.train_ds,batch_size=64,collate_fn=data_collate)\n",
    "with torch.no_grad():\n",
    "    for x,y in iter(dl):\n",
    "        ls = learnAEInit.model.getLS(x.cuda())\n",
    "        out.append(ls)\n",
    "out = torch.cat(out).cpu().detach().numpy()\n",
    "\n",
    "kmeans = KMeans(n_clusters=data.train_ds.c,n_init=20)\n",
    "kmeans.fit_predict(out)\n",
    "\n",
    "def assignClusters(x):\n",
    "    x = resample(x[1:],96)\n",
    "    ls = learnAEInit.model.getLS(torch.tensor(x,dtype=torch.float).unsqueeze(0).cuda())\n",
    "    pred =  kmeans.predict(ls.cpu().detach().numpy())[0]\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "src = TimeSeriesList.from_csv_list(ucr.get_csv_files(dataset_name),labelCol=0,processor=Resample())\n",
    "dataAEInit = src.filter_out_idx(valIdxs)\n",
    "dataAEInit = dataAEInit.no_split()\n",
    "dataAEInit = dataAEInit.label_from_func(assignClusters)\n",
    "dataAEInit = dataAEInit.databunch(bs=bs,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(dataAEInit.train_ds.y.items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learnClusterInit = Learner(data,learnAE.model.cluster,loss_func=F.cross_entropy,metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:48 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>1.877053</th>\n",
       "    <th>1.377259</th>\n",
       "    <th>0.481818</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>1.388547</th>\n",
       "    <th>1.470252</th>\n",
       "    <th>0.522222</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>1.218181</th>\n",
       "    <th>1.601922</th>\n",
       "    <th>0.502525</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>1.315376</th>\n",
       "    <th>1.415524</th>\n",
       "    <th>0.451010</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>1.258670</th>\n",
       "    <th>1.499835</th>\n",
       "    <th>0.481313</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>6</th>\n",
       "    <th>1.225418</th>\n",
       "    <th>1.446105</th>\n",
       "    <th>0.486869</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>7</th>\n",
       "    <th>1.147927</th>\n",
       "    <th>1.547378</th>\n",
       "    <th>0.491919</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>8</th>\n",
       "    <th>1.126443</th>\n",
       "    <th>1.365668</th>\n",
       "    <th>0.559596</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>9</th>\n",
       "    <th>0.946688</th>\n",
       "    <th>1.723986</th>\n",
       "    <th>0.519697</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>10</th>\n",
       "    <th>0.787562</th>\n",
       "    <th>1.612592</th>\n",
       "    <th>0.548485</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>11</th>\n",
       "    <th>0.736719</th>\n",
       "    <th>2.054502</th>\n",
       "    <th>0.508081</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>12</th>\n",
       "    <th>0.646941</th>\n",
       "    <th>1.894672</th>\n",
       "    <th>0.581818</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>13</th>\n",
       "    <th>0.505790</th>\n",
       "    <th>2.188583</th>\n",
       "    <th>0.534343</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>14</th>\n",
       "    <th>0.314599</th>\n",
       "    <th>2.206996</th>\n",
       "    <th>0.543434</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>15</th>\n",
       "    <th>0.202570</th>\n",
       "    <th>2.247856</th>\n",
       "    <th>0.576768</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>16</th>\n",
       "    <th>0.105510</th>\n",
       "    <th>2.412492</th>\n",
       "    <th>0.583333</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>17</th>\n",
       "    <th>0.049539</th>\n",
       "    <th>2.560115</th>\n",
       "    <th>0.572727</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>18</th>\n",
       "    <th>0.029894</th>\n",
       "    <th>2.576289</th>\n",
       "    <th>0.576263</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>19</th>\n",
       "    <th>0.016012</th>\n",
       "    <th>2.599968</th>\n",
       "    <th>0.578788</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>20</th>\n",
       "    <th>0.011139</th>\n",
       "    <th>2.605683</th>\n",
       "    <th>0.578788</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learnClusterInit.fit_one_cycle(20,1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c,m in enumerate(learnAE.model.aes):\n",
    "    src = TimeSeriesList.from_csv_list(ucr.get_csv_files(dataset_name),labelCol=0,processor=Resample())\n",
    "    dataExpert = src.filter_out_idx(valIdxs)\n",
    "    dataExpert = dataExpert.no_split()\n",
    "    dataExpert.train.filter_by_func(lambda x: assignClusters(x) == c)\n",
    "    dataExpert = dataExpert.label_from_self()\n",
    "    dataExpert = dataExpert.databunch(bs=4,num_workers=0)\n",
    "    \n",
    "    learnExpert = Learner(dataExpert,m,loss_func=AELoss)\n",
    "    learnExpert.fit_one_cycle(5,1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:00 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>1.060426</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.985367</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.965654</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.898124</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>0.802084</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>6</th>\n",
       "    <th>0.716432</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>7</th>\n",
       "    <th>0.635550</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>8</th>\n",
       "    <th>0.597151</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>9</th>\n",
       "    <th>0.547002</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>10</th>\n",
       "    <th>0.503328</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Total time: 00:00 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>1.099081</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>1.032355</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.951976</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.893443</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>0.830667</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>6</th>\n",
       "    <th>0.761764</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>7</th>\n",
       "    <th>0.695304</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>8</th>\n",
       "    <th>0.643739</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>9</th>\n",
       "    <th>0.590973</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>10</th>\n",
       "    <th>0.552113</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Total time: 00:00 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>1.077224</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>1.008290</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.955195</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.861006</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>0.757190</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>6</th>\n",
       "    <th>0.676751</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>7</th>\n",
       "    <th>0.598056</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>8</th>\n",
       "    <th>0.535293</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>9</th>\n",
       "    <th>0.483133</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>10</th>\n",
       "    <th>0.441026</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Total time: 00:00 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>1.056646</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.994214</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.927890</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.809273</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>0.723959</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>6</th>\n",
       "    <th>0.644767</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>7</th>\n",
       "    <th>0.597317</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>8</th>\n",
       "    <th>0.532441</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>9</th>\n",
       "    <th>0.483826</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>10</th>\n",
       "    <th>0.454376</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Total time: 00:00 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>1.067476</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>1.002641</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.987068</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.897574</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>0.811551</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>6</th>\n",
       "    <th>0.744630</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>7</th>\n",
       "    <th>0.671986</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>8</th>\n",
       "    <th>0.609906</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>9</th>\n",
       "    <th>0.562215</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>10</th>\n",
       "    <th>0.532331</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Total time: 00:00 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>1.031040</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.941828</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.910953</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.869127</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>0.778186</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>6</th>\n",
       "    <th>0.727049</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>7</th>\n",
       "    <th>0.657575</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>8</th>\n",
       "    <th>0.602799</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>9</th>\n",
       "    <th>0.558779</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>10</th>\n",
       "    <th>0.528167</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Total time: 00:00 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>1.081624</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>1.030462</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.953761</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.867896</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>0.775339</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>6</th>\n",
       "    <th>0.710761</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>7</th>\n",
       "    <th>0.633717</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>8</th>\n",
       "    <th>0.572890</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>9</th>\n",
       "    <th>0.528989</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>10</th>\n",
       "    <th>0.492527</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Total time: 00:00 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>1.048855</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.999273</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.907800</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.824950</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>0.746260</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>6</th>\n",
       "    <th>0.680167</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>7</th>\n",
       "    <th>0.642973</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>8</th>\n",
       "    <th>0.598781</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>9</th>\n",
       "    <th>0.548385</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>10</th>\n",
       "    <th>0.506800</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Total time: 00:00 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>1.063784</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.957814</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.893077</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.836349</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>0.746387</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>6</th>\n",
       "    <th>0.693338</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>7</th>\n",
       "    <th>0.648483</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>8</th>\n",
       "    <th>0.593870</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>9</th>\n",
       "    <th>0.554925</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>10</th>\n",
       "    <th>0.515399</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Total time: 00:00 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>1.094623</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>1.038693</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.977180</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.878901</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>0.819255</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>6</th>\n",
       "    <th>0.744536</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>7</th>\n",
       "    <th>0.688277</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>8</th>\n",
       "    <th>0.631247</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>9</th>\n",
       "    <th>0.579034</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>10</th>\n",
       "    <th>0.530782</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Total time: 00:00 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>1.070312</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>1.034127</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>0.974269</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>0.835119</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>0.723476</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>6</th>\n",
       "    <th>0.634145</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>7</th>\n",
       "    <th>0.564484</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>8</th>\n",
       "    <th>0.500232</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>9</th>\n",
       "    <th>0.447612</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>10</th>\n",
       "    <th>0.402224</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for c,m in enumerate(learnAE.model.aes):\n",
    "    d = data.train_ds.x.items.copy()\n",
    "    src = TimeSeriesList.from_numpy(d,labeled=0)\n",
    "    src = src.filter_by_func(lambda x: int(x[0]) - 1 == c)\n",
    "    dataExpert = src.no_split()\n",
    "    dataExpert = dataExpert.label_from_self()\n",
    "    dataExpert = dataExpert.databunch(bs=4,num_workers=0)\n",
    "    \n",
    "    learnExpert = Learner(dataExpert,m,loss_func=AELoss)\n",
    "    learnExpert.fit_one_cycle(10,1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(learnAE.model.state_dict(),\"init.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "learnAE.model.load_state_dict(torch.load(\"init.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learnAE.lr_find()\n",
    "learnAE.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learnAE = Learner(dataAE,learnAE.model,loss_func=MOALoss(),callback_fns=[ClusterAccuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:24 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>cluster_accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>51.454105</th>\n",
       "    <th>60.328915</th>\n",
       "    <th>0.990909</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learnAE.fit_one_cycle(1,1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(dataAE.train_dl))\n",
    "learnAE.model.eval()\n",
    "ps,recon,ts = learnAE.model(x)\n",
    "ps = torch.softmax(ps,dim=1)\n",
    "ps = torch.argmax(ps,dim=1)\n",
    "fig, axes = plt.subplots(3,3,figsize=(16,14))\n",
    "for i,ax in enumerate(axes.flatten()):\n",
    "    pred = ps[i].item()\n",
    "    ax.plot(x[i])\n",
    "    ax.plot(recon[pred][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optional: Visualize latent space\n",
    "learnAE.model.eval()\n",
    "out = []\n",
    "classes = []\n",
    "with torch.no_grad():\n",
    "    for x,y in iter(data.valid_dl):\n",
    "        ls = learnAE.model.mean(learnAE.model.conv(x.unsqueeze(1))[0].squeeze(-1))\n",
    "        out.append(ls)\n",
    "        classes.append(y)\n",
    "out = torch.cat(out).cpu().detach().numpy()\n",
    "classes = torch.cat(classes).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "f = pca.fit(out.T)\n",
    "f = f.components_.T\n",
    "plt.subplots(figsize=(20,15))\n",
    "style = classes if data.train_ds.c < 8 else None\n",
    "sns.scatterplot(x=f[:,0],y=f[:,1],hue=classes,palette=\"Dark2\",style=style,legend=\"full\",s=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2)\n",
    "f = tsne.fit_transform(out)\n",
    "plt.subplots(figsize=(20,15))\n",
    "sns.scatterplot(x=f[:,0],y=f[:,1],hue=classes,palette=\"Dark2\",style=style,legend=\"full\",s=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Traditional transfer\n",
    "Here we train a classifier by just adding a classifier head onto the encoder from the previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learnDT = Learner(data,BasicClassifier(data.train_ds.c,8,8),loss_func=F.cross_entropy,metrics=[accuracy],\n",
    "                 callback_fns=BnFreeze,bn_wd=False,train_bn=False)\n",
    "learnDT.split([*learnDT.model.conv.layers,learnDT.model.conv.avg,learnDT.model.out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the parameters from the encoder\n",
    "learnDT.model.conv.load_state_dict(learnAE.model.cluster.conv.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freeze up to the classifier layer\n",
    "learnDT.freeze_to(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learnDT.fit_one_cycle(20,1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Fine tune\n",
    "learnDT.unfreeze()\n",
    "learnDT.fit_one_cycle(100,1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: Sidekick network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "learnSidekick = Learner(data,SidekickConvnet(data.train_ds.c,8,8,8), loss_func=F.cross_entropy,metrics=[accuracy],\n",
    "                        callback_fns=BnFreeze,bn_wd=False,train_bn=False)\n",
    "learnSidekick.split([learnSidekick.model.hero,learnSidekick.model.layers[0],learnSidekick.model.out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 11])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learnSidekick.model(next(iter(data.train_dl))[0]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "learnSidekick.model.hero.load_state_dict(learnAE.model.cluster.conv.state_dict())\n",
    "learnSidekick.freeze_to(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learnSidekick.lr_find()\n",
    "learnSidekick.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='20', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/20 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='progress-bar-interrupted' max='55', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      Interrupted\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 8.00 GiB total capacity; 570.49 MiB already allocated; 30.06 MiB free; 9.01 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-b00bcf218eaa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlearnSidekick\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1e-3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\fastai\\train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[1;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[0;32m     20\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start, tot_epochs=tot_epochs, \n\u001b[0;32m     21\u001b[0m                                        start_epoch=start_epoch))\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mlr_find\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mLearner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\fastai\\basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallback_fns\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m         fit(epochs, self.model, self.loss_func, opt=self.opt, data=self.data, metrics=self.metrics,\n\u001b[1;32m--> 178\u001b[1;33m             callbacks=self.callbacks+callbacks)\n\u001b[0m\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m->\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\fastai\\utils\\mem.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    107\u001b[0m                 tb_clear_frames == \"1\"):\n\u001b[0;32m    108\u001b[0m                 \u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_ref_free_exc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# must!\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mraise\u001b[0m \u001b[1;31m# re-raises the exact last exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\fastai\\utils\\mem.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m             if (\"CUDA out of memory\" in str(e) or\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\fastai\\basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\fastai\\basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_backward_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0mcb_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_backward_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \"\"\"\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 8.00 GiB total capacity; 570.49 MiB already allocated; 30.06 MiB free; 9.01 MiB cached)"
     ]
    }
   ],
   "source": [
    "learnSidekick.fit_one_cycle(20,1e-3,wd=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
